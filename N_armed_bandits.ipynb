{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Binary Bandit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random\n","import matplotlib.pyplot as plt\n","\n","# Define a BinaryBandit class to simulate the bandit problem\n","class BinaryBandit:\n","    def __init__(self):\n","        # Set the number of arms to 2\n","        self.n_arms = 2\n","    \n","    # Define a method to return the possible actions (arms) of the bandit problem\n","    def actions(self):\n","        return list(range(self.n_arms))\n","    \n","    # Define a method to simulate a pull of an arm and return the resulting reward\n","    def pull_arm(self, action ,p):\n","        # Define the probability of success for each arm\n","        rand = random.random()\n","        if rand < p[action]:\n","            return 1\n","        else:\n","            return 0\n","\n","# Define an eGreedy function to implement the epsilon-greedy algorithm\n","def eGreedy(my_bandit, epsilon, max_iteration,p):\n","    # Initialization\n","    Q = [0] * my_bandit.n_arms\n","    count = [0] * my_bandit.n_arms\n","    R = []\n","    R_avg = [0]\n","    # Set the maximum number of iterations\n","    max_iter = max_iteration\n","    \n","    # Incremental Implementation\n","    for i in range(1, max_iter):\n","        # Choose the action to take based on the current Q values and the exploration/exploitation tradeoff\n","        if random.random() > epsilon:\n","            # Exploit: Choose the action with the highest Q value\n","            action = Q.index(max(Q))\n","        else:\n","            # Explore: Choose a random action\n","            action = random.choice(my_bandit.actions())\n","        # Simulate a pull of the arm and get the resulting reward\n","        reward = my_bandit.pull_arm(action,p)\n","        R.append(reward)\n","        # Update the count and Q values for the chosen action\n","        count[action] += 1\n","        Q[action] += (reward - Q[action]) / count[action]\n","        # Calculate the average reward so far\n","        R_avg.append(R_avg[-1] + (reward - R_avg[-1]) / i)\n","\n","    # Return the final Q values and the history of rewards\n","    return Q, R_avg, R\n","\n","# Set the random seed for reproducibility\n","random.seed(10)\n","\n","# Initialize the binary bandit problem\n","my_bandit = BinaryBandit()\n","\n","# Apply the epsilon-greedy algorithm to the problem with a fixed exploration rate of R and maximum N iterations\n","R = 0.2\n","N = 100 \n","p1 = [0.36 , 0.6 ]\n","p2 = [0.2 , 0.8]\n","\n","# Plot the average reward and reward per iteration bandit 1\n","Q, R_avg, R = eGreedy(my_bandit, R, N , p1)\n","print(\"Bandit1 : \")\n","print(p1)\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","ax1.plot(R_avg)\n","ax1.set_title(\"Average rewards vs Iteration\")\n","ax1.set_xlabel(\"Iteration\")\n","ax1.set_ylabel(\"Average Reward\")\n","ax2.plot(R)\n","ax2.set_title(\"Reward per iteration\")\n","ax2.set_xlabel(\"Iteration\")\n","ax2.set_ylabel(\"Reward\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Q2 : Code for n-Arm Bandit with modified Îµ-greedy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random\n","import matplotlib.pyplot as plt\n","\n","# Define the bandit environment class\n","class Bandit(object):\n","    def __init__(self, num_arms):\n","        # num_arms = number of arms in the bandit\n","        self.num_arms = num_arms\n","        # Assign same initial expected reward to all arms\n","        self.expected_rewards = [10] * num_arms \n","        \n","    def actions(self):\n","        # Returns the actions available in the bandit environment\n","        return list(range(0, self.num_arms))\n","        \n","    def reward(self, action):\n","        # Update the expected rewards of all the arms by adding some noise\n","        for i in range(len(self.expected_rewards)):\n","            # Add some noise to the expected reward using Gaussian distribution\n","            self.expected_rewards[i] += random.gauss(0, 0.1)\n","        \n","        # Calculate the reward obtained on selecting the specified action\n","        # Add some noise to the reward using Gaussian distribution\n","        return self.expected_rewards[action] + random.gauss(0, 0.01)\n","         \n","\n","def e_greedy(bandit, epsilon, max_iteration):\n","    # epsilon: the probability of selecting a random action (exploration)\n","    # max_iteration: maximum number of iterations\n","    \n","    # Initialize q_values for each arm to zero\n","    q_values = [0] * bandit.num_arms \n","    # Initialize action_counts for each arm to zero\n","    action_counts = [0] * bandit.num_arms \n","    # Initialize the total reward to zero\n","    total_reward = 0 \n","    # To store the rewards obtained at each iteration\n","    rewards = [] \n","    # To store the average rewards obtained until each iteration\n","    avg_rewards = [0] \n","    # Maximum iterations\n","    max_iter = max_iteration\n","\n","    # Implement the e-greedy algorithm\n","    for i in range(1, max_iter):\n","        if random.random() > epsilon:\n","            # Exploit (greedy action)\n","            action = q_values.index(max(q_values))\n","        else:\n","            # Explore (random action)\n","            action = random.choice(bandit.actions())\n","\n","        # Get the reward for the selected action\n","        reward = bandit.reward(action)\n","        rewards.append(reward)\n","        # Increment the action count for the selected action\n","        action_counts[action] += 1\n","        # Update the q_value for the selected action using incremental update rule\n","        q_values[action] += (reward - q_values[action]) / action_counts[action]\n","        # Update the total reward obtained so far\n","        total_reward += reward\n","        # Calculate the average reward and store it\n","        avg_rewards.append(total_reward / i)\n","        \n","    return q_values, avg_rewards, rewards\n","\n","# Set the random seed for reproducibility\n","random.seed(10)\n","\n","# Create a bandit environment with 10 arms\n","my_bandit = Bandit(10)\n","\n","# Run the e-greedy algorithm with epsilon=0.36 and maximum iterations=20000\n","q_values, avg_rewards, rewards = e_greedy(my_bandit, 0.36, 20000)\n","\n","# Print the actual expected rewards and the recovered expected rewards\n","print(\"Actual\\tRecovered \")\n","for i, j in zip(my_bandit.expected_rewards, q_values):\n","    print(f\"{i:.3f}\\t{j:.3f}\")\n","\n","# Plot the average rewards obtained and the rewards obtained at each iteration\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","ax1.plot(R_avg)\n","ax1.set_title(\"Average rewards V/s Iteration\")\n","ax1.set_xlabel(\"Iteration\")\n","ax1.set_ylabel(\"Average Reward\")\n","ax2.plot(R)\n","ax2.set_title(\"Reward per iteration\")\n","ax2.set_xlabel(\"Iteration\")\n","ax2.set_ylabel(\"Reward\")\n","fig.suptitle(\"Unmodified Epsilon Greedy Policy\")\n","plt.show()"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
